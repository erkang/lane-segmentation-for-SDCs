{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "from helper import (\n",
    "    weight_variable, \n",
    "    bias_variable, \n",
    "    conv2d, \n",
    "    conv2d_transpose_strided\n",
    ")\n",
    "\n",
    "import project_tests as tests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'data/vgg/variables/variables'\n"
     ]
    }
   ],
   "source": [
    "vgg_path = 'data/vgg'\n",
    "sess = tf.Session()\n",
    "\n",
    "someinfo = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f563d9e3fd0>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = np.array([n for n in g.as_graph_def().node if '_out' in n.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req = ['image_input','keep_prob','layer3_out','layer4_out','layer7_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'image_input:0' shape=(?, ?, ?, 3) dtype=float32>,\n",
       " <tf.Tensor 'keep_prob:0' shape=<unknown> dtype=float32>,\n",
       " <tf.Tensor 'layer3_out:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
       " <tf.Tensor 'layer4_out:0' shape=(?, ?, ?, 512) dtype=float32>,\n",
       " <tf.Tensor 'layer7_out:0' shape=(?, ?, ?, 4096) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[g.get_tensor_by_name( r + \":0\") for r in req]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer3_out)\n",
    "    \"\"\" \n",
    "    _ = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n",
    "    \n",
    "    return (tf.get_default_graph().get_tensor_by_name( r + \":0\") for r in ['image_input','keep_prob','layer3_out','layer4_out','layer7_out'])\n",
    "\n",
    "tests.test_load_vgg(load_vgg, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p(x):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 3 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 7 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "#     p(vgg_layer3_out)\n",
    "#     p(vgg_layer4_out)\n",
    "#     p(vgg_layer7_out)\n",
    "    \n",
    "    W8 = weight_variable([1, 1, 4096, num_classes], name=\"W8_1\")\n",
    "    b8 = bias_variable([num_classes], name=\"b8_1\")\n",
    "    conv8 = conv2d(vgg_layer7_out, W8, b8)\n",
    "#     p(conv8)\n",
    "    \n",
    "    \n",
    "    deconv_shape1 = vgg_layer4_out.get_shape()\n",
    "    W_t1 = weight_variable([4, 4, deconv_shape1[3].value, num_classes], name=\"W_t1\")\n",
    "    b_t1 = bias_variable([deconv_shape1[3].value], name=\"b_t1\")\n",
    "    conv_t1 = conv2d_transpose_strided(conv8, W_t1, b_t1, output_shape=tf.shape(vgg_layer4_out))\n",
    "    fuse_1 = tf.add(conv_t1, vgg_layer4_out, name=\"fuse_1\")\n",
    "#     p(fuse_1)\n",
    "    \n",
    "    deconv_shape2 = vgg_layer3_out.get_shape()\n",
    "    W_t2 = weight_variable([4, 4, deconv_shape2[3].value, deconv_shape1[3].value], name=\"W_t2\")\n",
    "    b_t2 = bias_variable([deconv_shape2[3].value], name=\"b_t2\")\n",
    "    conv_t2 = conv2d_transpose_strided(fuse_1, W_t2, b_t2, output_shape=tf.shape(vgg_layer3_out))\n",
    "    fuse_2 = tf.add(conv_t2, vgg_layer3_out, name=\"fuse_2\")\n",
    "#     p(fuse_2)\n",
    "    \n",
    "    batch_size = tf.shape(fuse_2)[0]\n",
    "    # height = tf.shape(fuse_2)[1]\n",
    "    # width = tf.shape(fuse_2)[2]\n",
    "    height, width = 160, 576\n",
    "#     print(batch_size, height, width, num_classes)\n",
    "    deconv_shape3 = tf.stack([batch_size, height, width, num_classes])\n",
    "#     p(deconv_shape3)\n",
    "    \n",
    "    # deconv_shape3 = [None, None, None, num_classes]\n",
    "    W_t3 = weight_variable([16, 16, num_classes, deconv_shape2[3].value], name=\"W_t3\")\n",
    "    b_t3 = bias_variable([num_classes], name=\"b_t3\")\n",
    "    conv_t3 = conv2d_transpose_strided(fuse_2, W_t3, b_t3, output_shape=deconv_shape3, stride=8)\n",
    "#     p(conv_t3)\n",
    "    \n",
    "    return conv_t3\n",
    "\n",
    "tests.test_layers(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    correct_label = tf.reshape(correct_label, (-1, num_classes))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label, name=\"entropy\"))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    # optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    \n",
    "    grads = optimizer.compute_gradients(loss, var_list=tf.trainable_variables())\n",
    "    train_op = optimizer.apply_gradients(grads)\n",
    "    \n",
    "    return logits, train_op, loss\n",
    "\n",
    "tests.test_optimize(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \"\"\"\n",
    "    Train neural network and print out the loss during training.\n",
    "    :param sess: TF Session\n",
    "    :param epochs: Number of epochs\n",
    "    :param batch_size: Batch size\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "    :param input_image: TF Placeholder for input images\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    lossess = []\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        for idx, (train_images, train_gt) in enumerate(get_batches_fn(batch_size)):\n",
    "            feed_dict = {input_image: train_images, correct_label: train_gt, keep_prob: 0.85}\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            \n",
    "            if idx%20 == 0:\n",
    "                train_loss = sess.run([cross_entropy_loss], feed_dict=feed_dict)\n",
    "                print(\"[{}/{}] Loss: {:.2f}\".format(idx, epoch, train_loss[0]))\n",
    "                lossess.append(train_loss[0])\n",
    "    \n",
    "    return lossess\n",
    "                \n",
    "# tests.test_train_nn(train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n",
      "INFO:tensorflow:Restoring parameters from b'./data/vgg/variables/variables'\n",
      "[0/0] Loss: 127.42\n",
      "[20/0] Loss: 4.62\n",
      "[0/1] Loss: 0.95\n",
      "[20/1] Loss: 0.33\n",
      "[0/2] Loss: 0.25\n",
      "[20/2] Loss: 0.15\n",
      "[0/3] Loss: 0.19\n",
      "[20/3] Loss: 0.14\n",
      "Training Finished. Saving test images to: ./runs/1499290655.9898217\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "image_shape = (160, 576)\n",
    "data_dir = './data'\n",
    "runs_dir = './runs'\n",
    "tests.test_for_kitti_dataset(data_dir)\n",
    "\n",
    "# Download pretrained vgg model\n",
    "helper.maybe_download_pretrained_vgg(data_dir)\n",
    "\n",
    "# OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n",
    "# You'll need a GPU with at least 10 teraFLOPS to train on.\n",
    "# https://www.cityscapes-dataset.com/\n",
    "\n",
    "tf.reset_default_graph()\n",
    "    \n",
    "vgg_path = './data/vgg'\n",
    "epochs, batch_size, learning_rate = 4, 8, 1e-4\n",
    "with tf.Session() as sess:\n",
    "    # Create function to get batches\n",
    "    get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
    "    \n",
    "    # OPTIONAL: Augment Images for better results\n",
    "    #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n",
    "    \n",
    "    correct_label = tf.placeholder(tf.float32, [None, None, None, num_classes])\n",
    "    \n",
    "    # TODO: Build NN using load_vgg, layers, and optimize function\n",
    "    input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
    "    layers_output = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
    "    logits, train_op, cross_entropy_loss = optimize(layers_output, correct_label, learning_rate, num_classes)\n",
    "    \n",
    "    # TODO: Train NN using the train_nn function\n",
    "    lossess = train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image, correct_label, keep_prob, learning_rate)\n",
    "    \n",
    "    # TODO: Save inference data using helper.save_inference_samples\n",
    "    helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3rhFkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd29829dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossess)\n",
    "plt.ylim([0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-13-5c2824508f80>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-5c2824508f80>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Image(filename='./runs/1499290655.9898217/um_000006\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./runs/1499290655.9898217/um_000006\n",
    "      .png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
